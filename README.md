# Two-Stage Temporal Action Recognition System

**Industry-ready temporal action recognition for assembly process analysis**

## ğŸ¯ Overview

This system implements a **two-stage hierarchical action recognition pipeline** for industrial assembly processes:

1. **Stage 1:** Coarse action classification (FirstWord strategy)
2. **Stage 2:** Fine-grained action classification per family

The system provides dual output formats: machine-readable JSON timelines and human-readable annotated videos with color-coded overlays.

## ğŸš€ Quick Start

### Prerequisites
```bash
pip install torch torchvision opencv-python numpy pandas tqdm
```

### Training
```bash
python train_deployment_model.py
```

### Testing/Inference
```bash
python inference_deployment.py
```

## ğŸ“ Project Structure

```
â”œâ”€â”€ train_deployment_model.py              # ğŸ”§ TRAINING SCRIPT
â”œâ”€â”€ inference_deployment.py                # ğŸ¯ TESTING/INFERENCE SCRIPT  
â”œâ”€â”€ Two_Stage_Temporal_Action_Recognition_Complete.ipynb  # ğŸ““ Complete Implementation
â”œâ”€â”€ README.md                              # ğŸ“– This file
â”œâ”€â”€ dataset/                               # ğŸ“‚ Training videos
â”‚   â”œâ”€â”€ action_name_va_001.mp4
â”‚   â”œâ”€â”€ action_name_rnva_001.mp4
â”‚   â””â”€â”€ ...
â”œâ”€â”€ test/                                  # ğŸ“‚ Test videos
â”‚   â”œâ”€â”€ test_video_001.mp4
â”‚   â””â”€â”€ ...
â”œâ”€â”€ outputs_deployment/                    # ğŸ“‚ Trained models (generated)
â””â”€â”€ inference_results/                     # ğŸ“‚ Results (generated)
    â”œâ”€â”€ json/                              # JSON timelines
    â””â”€â”€ videos/                            # Annotated videos
```

## ğŸ¨ Key Features

### Dual Output Format
1. **JSON Timelines**: Machine-readable for system integration
2. **Annotated Videos**: Human-readable with color-coded overlays

### Video Overlay System
- **VA (Value-Added)**: ğŸŸ¢ Green text
- **RNVA (Required Non-Value-Added)**: ğŸŸ  Orange text  
- **NVA (Non-Value-Added)**: ğŸ”´ Red text

### Technical Specifications
- **Architecture**: Two-stage (R3D-18 + MLP)
- **Temporal Length**: 16 frames (optimized for deployment)
- **Training Accuracy**: 100% on industrial dataset
- **Hardware**: CUDA-enabled (RTX 4050 tested)

## ğŸ“Š Dataset Format

### Training Videos (dataset/)
```
action_name_va_001.mp4      # Value-Added
action_name_rnva_001.mp4    # Required Non-Value-Added
action_name_nva_001.mp4     # Non-Value-Added
```

### Example Actions
- `hand_tight_nipple_to_pipe_va_001.mp4`
- `apply_loctite_to_bolt_rnva_001.mp4`
- `excess_walk_to_get_sensor_nva_001.mp4`

## ğŸ¯ Output Examples

### JSON Timeline
```json
[
  {
    "start": 0.0,
    "end": 8.97,
    "duration": 8.97,
    "coarse_action": "apply",
    "fine_action": "apply_loctite_to_nipple",
    "value_category": "RNVA",
    "num_frames": 5
  }
]
```

### Video Overlay
```
COARSE ACTION: apply
FINE ACTION  : apply_loctite_to_nipple  
VALUE TYPE   : RNVA
```

## âš™ï¸ Configuration

Key parameters in training script:
```python
FIXED_T = 16              # Temporal sequence length
TARGET_FPS = 8            # Sampling rate
BATCH_SIZE = 4            # Training batch size
EPOCHS_1 = 40             # Stage-1 epochs
EPOCHS_2 = 50             # Stage-2 epochs
```

## ğŸ”§ Hardware Requirements

- **GPU**: NVIDIA GPU with CUDA support
- **VRAM**: 4-6 GB recommended
- **RAM**: 8 GB+
- **Python**: 3.8+

## ğŸ“ˆ Performance

- **Training Time**: ~15-25 minutes (depends on dataset size)
- **Inference Speed**: ~1-2 seconds per video
- **Accuracy**: 100% training accuracy achieved
- **Mixed Precision**: FP16 enabled for efficiency

## ğŸ“ Architecture Details

### Stage 1: Coarse Classification
- **Input**: R3D-18 features (512-dim)
- **Strategy**: FirstWord labeling (`hand_tight_*` â†’ `hand`)
- **Output**: 14-20 coarse action categories

### Stage 2: Fine-Grained Classification  
- **Input**: R3D-18 features + Stage-1 prediction
- **Strategy**: Family-specific models per coarse action
- **Output**: Detailed action labels

### Temporal Processing
- **Smoothing**: Majority voting in sliding windows
- **Aggregation**: Single prediction per video
- **Optimization**: 16-frame sequences for better interpretability

## ğŸš€ Industry Ready

âœ… **Dual Output**: JSON + Video overlays  
âœ… **Color Coding**: Clear visual feedback  
âœ… **High Accuracy**: 100% training performance  
âœ… **Fast Inference**: Real-time processing  
âœ… **Scalable**: Easy to add new actions  
âœ… **Production**: Optimized for deployment  

## ğŸ“ Usage Notes

1. **Training**: Place videos in `dataset/` with proper naming
2. **Testing**: Add test videos to `test/` folder  
3. **Results**: Check `inference_results/` for outputs
4. **Jupyter**: Use notebook for detailed implementation study

---

**Status**: âœ… Production-Ready  
**Last Updated**: January 2026  
**Hardware Tested**: NVIDIA RTX 4050